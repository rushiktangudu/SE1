{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "I will explain your medical report to you in simple terms.  \n",
    "- I will speak directly to you as if I am your doctor.  \n",
    "- All medical terms will be replaced with words that are easy to understand.  \n",
    "- I will focus on making sure you fully grasp your condition and what it means for your health.  \n",
    "\n",
    "Conversation History:  \n",
    "{context}  \n",
    "\n",
    "Your Report:  \n",
    "{question}  \n",
    "\n",
    "Your Health Explained:  \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "model = OllamaLLM(model=\"wizardlm2:latest\")\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "import pyttsx3\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Set properties (optional)\n",
    "engine.setProperty(\"rate\", 150)  # Speed of speech\n",
    "engine.setProperty(\"volume\", 1.0)  # Volume level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(image_path):\n",
    "    reader = easyocr.Reader(['en'])  # English language\n",
    "    results = reader.readtext(image_path, detail=0)  # Extract text\n",
    "    return \" \".join(results)  # Combine extracted text into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r\"C:\\Users\\hyndh\\OneDrive\\Desktop\\ollama\\report.jpg\"\n",
    "\n",
    "extracted_text = extract_text(image_path)\n",
    "print(\"Extracted Text:\\n\", extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_conversation():\n",
    "    context = \"\"\n",
    "    print(\"Welcome to AI ChatBot!\")\n",
    "    \n",
    "    user_input = extracted_text  # Assuming extracted_text is defined earlier\n",
    "    \n",
    "    result = chain.invoke({\"context\": context, \"question\": user_input}).strip()  # Strip unnecessary text\n",
    "    result = result.split(\"</think>\")[-1].strip() \n",
    "    print(\"Bot:\", result)\n",
    "\n",
    "    context += f\"\\nUser: {user_input}\\nAI: {result}\"\n",
    "    return result,context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_context, bot_response = handle_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans AI-generated text by removing unwanted symbols like **bold markers**, \n",
    "    extra spaces, and unnecessary formatting.\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"\\*\\*(.*?)\\*\\*\", r\"\\1\", text)  # Remove bold markers (**text** -> text)\n",
    "    text = re.sub(r\"_+\", \" \", text)  # Replace multiple underscores with a space\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Remove extra spaces and trim\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = clean_text(conversation_context)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.say(cleaned_text)\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Load the IndicTrans2 model and tokenizer\n",
    "model_name = \"ai4bharat/indictrans-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "def translate_text(text, target_lang=\"hin\"):  # 'hin' for Hindi, 'tam' for Tamil, etc.\n",
    "    \"\"\"Translates English medical text to the target Indian language.\"\"\"\n",
    "    inputs = tokenizer(f\"translate to {target_lang}: {text}\", return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_length=1024)\n",
    "    translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return translated_text\n",
    "\n",
    "# Example: Translate medical report to Hindi\n",
    "english_text = \"\"\"Hello there! Let's go through your medical report and explain it in a way that's easy to understand. \n",
    "Imagine I'm your doctor, and I'm here to help you understand what your recent hospital stay and procedure involved.\"\"\"\n",
    "hindi_translation = translate_text(english_text, \"hin\")  # 'hin' for Hindi\n",
    "\n",
    "print(\"Translated Text:\", hindi_translation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtranslate import translate\n",
    "\n",
    "def translate_text(text, target_lang=\"hi\"):\n",
    "    return translate(text, target_lang)\n",
    "\n",
    "print(translate_text(\"Hello, how are you?\", \"hi\"))  # Hindi\n",
    "print(translate_text(\"Hello, how are you?\", \"te\"))  # Tamil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_text = translate_text(cleaned_text, \"te\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import simpleaudio as sa\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def speak(text, lang=\"hi\"):  # Change \"hi\" to other Indian languages if needed\n",
    "    # Convert text to speech\n",
    "    tts = gTTS(text, lang=lang)\n",
    "    tts.save(\"output.mp3\")  # Save as MP3\n",
    "\n",
    "    # Convert MP3 to WAV\n",
    "    sound = AudioSegment.from_mp3(\"output.mp3\")\n",
    "    sound.export(\"output.wav\", format=\"wav\")\n",
    "\n",
    "    # Play WAV file\n",
    "    wave_obj = sa.WaveObject.from_wave_file(\"output.wav\")\n",
    "    play_obj = wave_obj.play()\n",
    "    play_obj.wait_done()\n",
    "\n",
    "    # Clean up files\n",
    "    os.remove(\"output.mp3\")\n",
    "    os.remove(\"output.wav\")\n",
    "\n",
    "# Speak in Hindi\n",
    "speak(\"नमस्ते, आप कैसे हैं?\", \"hi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vosk import Model, KaldiRecognizer\n",
    "import wave\n",
    "\n",
    "model = Model(\"vosk-model-hi\")  # Change to vosk-model-ta, vosk-model-te, etc.\n",
    "rec = KaldiRecognizer(model, 16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "tts = gTTS(translated_text, lang=\"te\")  # Change \"hi\" for Hindi, \"ta\" for Tamil, etc.\n",
    "tts.save(\"output.mp3\")\n",
    "\n",
    "# Play the audio\n",
    "os.system(\"start output.mp3\")  # Windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
